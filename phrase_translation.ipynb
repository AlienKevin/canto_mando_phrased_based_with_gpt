{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sample of common traditional characters:  ['晉', '辱', '金', '斂', '訃', '嬌', '疏', '逼', '碟', '漬']\n"
     ]
    }
   ],
   "source": [
    "common_trad_chars = None\n",
    "\n",
    "with open(\"common_trad_chars.txt\", \"r\") as input_file:\n",
    "    common_trad_chars = set(input_file.read())\n",
    "\n",
    "print(\"A sample of common traditional characters: \", list(common_trad_chars)[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "can2man_table = defaultdict(list)\n",
    "\n",
    "with open(\"can2man_phrase_table.txt\", \"r\") as input_file:\n",
    "    for line in input_file.read().splitlines():\n",
    "        [can_word, man_word] = line.split(\"|\")\n",
    "        can2man_table[can_word].append(man_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5635 one-to-many mappings (10% out of 58511).\n",
      "Average number of Mandarin translations for one-to-many: 2.7531499556344277\n"
     ]
    }
   ],
   "source": [
    "num_one_to_many = 0\n",
    "avg_one_to_many = 0\n",
    "\n",
    "for can_word, man_words in can2man_table.items():\n",
    "    if len(man_words) > 1:\n",
    "        num_one_to_many += 1\n",
    "        avg_one_to_many += len(man_words)\n",
    "\n",
    "avg_one_to_many /= num_one_to_many\n",
    "\n",
    "print(\"Found {} one-to-many mappings ({:.0%} out of {}).\".format(num_one_to_many, num_one_to_many / len(can2man_table), len(can2man_table)))\n",
    "print(\"Average number of Mandarin translations for one-to-many: {}\".format(avg_one_to_many))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_match_translate(s, phrase_table):\n",
    "    man_phrases: list[list[str]] = []\n",
    "    oov_word = \"\"\n",
    "    while s:\n",
    "        longest_match = None\n",
    "        for phrase in phrase_table:\n",
    "            if s.startswith(phrase) and (longest_match is None or len(phrase) > len(longest_match)):\n",
    "                longest_match = phrase\n",
    "        if longest_match:\n",
    "            if len(oov_word) > 0:\n",
    "                man_phrases.append([oov_word])\n",
    "                oov_word = \"\"\n",
    "            can_original = [longest_match] if len(longest_match) <= 1 and all(c in common_trad_chars for c in longest_match) else []\n",
    "            man_phrase = phrase_table[longest_match]\n",
    "            man_phrases.append(can_original + man_phrase)\n",
    "            s = s[len(longest_match):].lstrip()\n",
    "        else:\n",
    "            oov_word += s[0]\n",
    "            s = s[1:].lstrip()\n",
    "    if len(oov_word) > 0:\n",
    "        man_phrases.append([oov_word])\n",
    "    # Merge anchor phrases (those with a single mandarin translation)\n",
    "    i = 0\n",
    "    merged_man_phrases = []\n",
    "    while i < len(man_phrases):\n",
    "        merged_phrase = \"\"\n",
    "        while i < len(man_phrases) and len(man_phrases[i]) == 1:\n",
    "            merged_phrase += man_phrases[i][0]\n",
    "            i += 1\n",
    "        if len(merged_phrase) > 0:\n",
    "            merged_man_phrases.append([merged_phrase])\n",
    "            merged_phrase = \"\"\n",
    "        else:\n",
    "            merged_man_phrases.append(man_phrases[i])\n",
    "            i += 1\n",
    "    return merged_man_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['不好意思', '勞', '勞駕', '有勞您', '請你', '請', '請教', '謝', '謝謝', '麻煩您'],\n",
       " ['你小聲點，我'],\n",
       " ['在此', '在這裡', '在這邊', '在那裡', '在那邊'],\n",
       " ['正在做'],\n",
       " ['事情', '東西'],\n",
       " ['。']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest_match_translate(\"唔該你細聲啲，我喺度做緊嘢。\", can2man_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, GPT2LMHeadModel\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-chinese')\n",
    "model = GPT2LMHeadModel.from_pretrained('ckiplab/gpt2-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# https://huggingface.co/docs/transformers/perplexity\n",
    "def get_most_fluent_sentence_index(candidates: list[str]) -> int:\n",
    "    encodings = [tokenizer(candidate, return_tensors=\"pt\") for candidate in candidates]\n",
    "    ppls = []\n",
    "    for encoding in encodings:\n",
    "        target_ids_list = []\n",
    "        seq_len = encoding.input_ids.size(1)\n",
    "        for end_loc in range(2, seq_len + 1, 2):\n",
    "            target_ids = encoding.input_ids[0].clone()\n",
    "            target_ids[end_loc:] = -100\n",
    "            target_ids_list.append(target_ids)\n",
    "        target_ids = torch.stack(target_ids_list)\n",
    "        input_ids = encoding.input_ids.expand(target_ids.shape)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, labels=target_ids)\n",
    "            ppl = outputs.loss.item() * seq_len\n",
    "            ppls.append(ppl)\n",
    "    return torch.argmin(torch.tensor(ppls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "\n",
    "# match any unicode punctuation character and anything after it\n",
    "punctuation_pattern = regex.compile(r\"\\p{P}+.*\", flags=regex.UNICODE)\n",
    "chinese_char_pattern = regex.compile(r\"[\\u4e00-\\u9fff]\")\n",
    "\n",
    "def chop_off_at_punctuation(s: str) -> str:\n",
    "    match = punctuation_pattern.search(s)\n",
    "    if match:\n",
    "        index = match.start()\n",
    "        return s[:index]\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "def chop_off_at_canto_char(s: str) -> str:\n",
    "    for i, c in enumerate(s):\n",
    "        if chinese_char_pattern.match(c) and not c in common_trad_chars:\n",
    "            return s[:i]\n",
    "    return s\n",
    "\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def can2man(s: str) -> str:\n",
    "    man_phrases = longest_match_translate(s, can2man_table)\n",
    "    # print(man_phrases)\n",
    "    for i, phrases in enumerate(man_phrases):\n",
    "        if len(phrases) == 1:\n",
    "            continue\n",
    "        else:\n",
    "            j = i + 1\n",
    "            while j < len(man_phrases) and man_phrases[j] == 1:\n",
    "                j += 1\n",
    "            backward_context = \"\".join(flatten(man_phrases[max(0, i-5):i]))\n",
    "            forward_context = \"\".join(flatten(man_phrases[i + 1:j]))\n",
    "            # forward context is too small\n",
    "            while len(forward_context) < 10 and j < len(man_phrases):\n",
    "                forward_context += man_phrases[j][0]\n",
    "                j += 1\n",
    "            forward_context = chop_off_at_canto_char(chop_off_at_punctuation(forward_context))\n",
    "            # print(f\"i={i} backward_context={backward_context}, forward_context={forward_context}\")\n",
    "            candidates = [backward_context + phrase + forward_context for phrase in man_phrases[i]]\n",
    "            j = get_most_fluent_sentence_index(candidates)\n",
    "            man_phrases[i] = [man_phrases[i][j]]\n",
    "    # print(man_phrases)\n",
    "    return \"\".join(flatten(man_phrases))\n",
    "\n",
    "import random\n",
    "def can2man_random(s: str) -> str:\n",
    "    man_phrases = longest_match_translate(s, can2man_table)\n",
    "    # print(man_phrases)\n",
    "    for i, phrases in enumerate(man_phrases):\n",
    "        if len(phrases) == 1:\n",
    "            continue\n",
    "        else:\n",
    "            man_phrases[i] = [random.choice(man_phrases[i])]\n",
    "    # print(man_phrases)\n",
    "    return \"\".join(flatten(man_phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "請你小聲點，我在這裡正在做東西。\n",
      "謝你小聲點，我在那裡正在做東西。\n"
     ]
    }
   ],
   "source": [
    "print(can2man(\"唔該你細聲啲，我喺度做緊嘢。\"))\n",
    "print(can2man_random(\"唔該你細聲啲，我喺度做緊嘢。\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "哪一個調整到一本書散了架子\n",
      "哪位製作到一本書皮開骨散\n"
     ]
    }
   ],
   "source": [
    "print(can2man(\"邊個整到本書甩皮甩骨\"))\n",
    "print(can2man_random(\"邊個整到本書甩皮甩骨\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "他舉重嗰時掬先度氣堅持先，終於破了世界紀錄\n",
      "她舉重嗰時掬先裡氣息堅持住，終於破了生活紀錄\n"
     ]
    }
   ],
   "source": [
    "print(can2man(\"佢舉重嗰時掬住度氣堅持住，終於破咗世界紀錄\"))\n",
    "print(can2man_random(\"佢舉重嗰時掬住度氣堅持住，終於破咗世界紀錄\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "現下男子100米的世界記錄是9.58秒。\n",
      "現而今男子100公尺的世界記錄是9.58秒。\n"
     ]
    }
   ],
   "source": [
    "print(can2man(\"而家男子100米嘅世界記錄係9.58秒。\"))\n",
    "print(can2man_random(\"而家男子100米嘅世界記錄係9.58秒。\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "絕對不可以同等，母語（粵語）一定是第一，至於英文你覺得重要不然問題，但地位不可以超越母語，你有見過其他國家（除了新加坡）會把母語ge地位擺是外語之後？\n",
      "絕對不可以同等，母語（粵語）一定是第一，至於英文你覺得重要可不是問題，但是地位不可以超越母語，你有見比其他國家（算術上的除法了新加坡）將會把母語ge地位擺設是外語之後？\n"
     ]
    }
   ],
   "source": [
    "print(can2man(\"絕對 唔 可以 同等 ， 母語 （ 粵語 ） 一 定係 第一 ， 至於 英文 你 覺得 重要 唔係 問題 ， 但 地位 唔 可以 超越 母語 ， 你 有 見 過 其他 國家 （ 除咗 新加坡 ） 會 將 母語 ge 地位 擺 係 外語 之後 ？\".replace(\" \", \"\")))\n",
    "print(can2man_random(\"絕對 唔 可以 同等 ， 母語 （ 粵語 ） 一 定係 第一 ， 至於 英文 你 覺得 重要 唔係 問題 ， 但 地位 唔 可以 超越 母語 ， 你 有 見 過 其他 國家 （ 除咗 新加坡 ） 會 將 母語 ge 地位 擺 係 外語 之後 ？\".replace(\" \", \"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:26<00:00, 37.52it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "with open(\"dev.can\", \"r\") as input_file, open(\"dev.pred.random.man\", \"w+\") as output_file:\n",
    "    for line in tqdm(input_file.read().splitlines()[0:1000]):\n",
    "        output_file.write(can2man_random(line) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80000/80000 [1:16:57<00:00, 17.32it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "with open(\"can.txt\", \"r\") as input_file, open(\"man_40K_to_120K.txt\", \"w+\") as output_file:\n",
    "    for line in tqdm(input_file.read().splitlines()[40000:40000*3]):\n",
    "        output_file.write(can2man_random(line) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'不好意思你小聲點，我在這裡正在做東西。'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can2man(\"唔該你細聲啲，我喺度做緊嘢。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'哪一個受傷一本書散了架子'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can2man(\"邊個整到本書甩皮甩骨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'他舉重什麼時候提升住程度人的精神狀態堅持住，終於打破了世界紀錄'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can2man(\"佢舉重嗰時掬住度氣堅持住，終於破咗世界紀錄\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'現下男子100公尺的世界記錄是9.58秒。'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can2man(\"而家男子100米嘅世界記錄係9.58秒。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [11:57<00:00,  1.39it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "with open(\"dev.can\", \"r\") as input_file, open(\"dev.pred.full.man\", \"w+\") as output_file:\n",
    "    for line in tqdm(input_file.read().splitlines()[0:1000]):\n",
    "        output_file.write(can2man(line) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identity charBLEU: 11.916798739593405\n",
      "Identity CHRF: 11.892985577296292\n",
      "\n",
      "Phrase-Random charBLEU: 16.844144675728426\n",
      "Phrase-Random CHRF: 17.04834182555853\n",
      "\n",
      "Phrase-Base charBLEU: 18.834564873844943\n",
      "Phrase-Base CHRF: 20.091559992795194\n",
      "\n",
      "Phrase-Wordshk charBLEU: 12.415971775936248\n",
      "Phrase-Wordshk CHRF: 16.061245936906026\n",
      "\n",
      "Phrase-Full charBLEU: 24.23631480403355\n",
      "Phrase-Full CHRF: 21.32881366574855\n"
     ]
    }
   ],
   "source": [
    "# Measure BLEU of base model\n",
    "\n",
    "import os\n",
    "import sacrebleu\n",
    "\n",
    "def eval_bleu(ref, hyp):\n",
    "    \"\"\"\n",
    "    Given a file of hypothesis and reference files,\n",
    "    evaluate the BLEU score using Moses scripts.\n",
    "    \"\"\"\n",
    "    assert os.path.isfile(ref) and os.path.isfile(hyp)\n",
    "    with open(ref, \"r\") as ref_file, open(hyp, \"r\") as hyp_file:\n",
    "        refs = [ref_file.read().splitlines()]\n",
    "        hyp = hyp_file.read().splitlines()\n",
    "        bleu = sacrebleu.BLEU(trg_lang=\"zh\")\n",
    "        return bleu.corpus_score(hyp, refs).score\n",
    "\n",
    "\n",
    "def eval_chrf(ref, hyp):\n",
    "    \"\"\"\n",
    "    Given a file of hypothesis and reference files,\n",
    "    evaluate the BLEU score using Moses scripts.\n",
    "    \"\"\"\n",
    "    assert os.path.isfile(ref) and os.path.isfile(hyp)\n",
    "    with open(ref, \"r\") as ref_file, open(hyp, \"r\") as hyp_file:\n",
    "        refs = [ref_file.read().splitlines()]\n",
    "        hyp = hyp_file.read().splitlines()\n",
    "        chrf = sacrebleu.CHRF()\n",
    "        return chrf.corpus_score(hyp, refs).score\n",
    "\n",
    "\n",
    "print(\"Identity charBLEU:\", eval_bleu(\"dev.man\", \"dev.can\"))\n",
    "print(\"Identity CHRF:\", eval_chrf(\"dev.man\", \"dev.can\"))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Phrase-Random charBLEU:\", eval_bleu(\"dev.man\", \"dev.pred.random.man\"))\n",
    "print(\"Phrase-Random CHRF:\", eval_chrf(\"dev.man\", \"dev.pred.random.man\"))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Phrase-Base charBLEU:\", eval_bleu(\"dev.man\", \"dev.pred.base.man\"))\n",
    "print(\"Phrase-Base CHRF:\", eval_chrf(\"dev.man\", \"dev.pred.base.man\"))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Phrase-Wordshk charBLEU:\", eval_bleu(\"dev.man\", \"dev.pred.wordshk.man\"))\n",
    "print(\"Phrase-Wordshk CHRF:\", eval_chrf(\"dev.man\", \"dev.pred.wordshk.man\"))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Phrase-Full charBLEU:\", eval_bleu(\"dev.man\", \"dev.pred.full.man\"))\n",
    "print(\"Phrase-Full CHRF:\", eval_chrf(\"dev.man\", \"dev.pred.full.man\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/kevin/Dev/classes/winter2023/eecs487/canto_mando_baseline_gpt/phrase_translation.ipynb Cell 23\u001b[0m in \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kevin/Dev/classes/winter2023/eecs487/canto_mando_baseline_gpt/phrase_translation.ipynb#X32sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mcantonese_18M_freq_10_up.txt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m input_file, \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mcantonese_18M_freq_10_up.pred.base.txt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw+\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m output_file:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kevin/Dev/classes/winter2023/eecs487/canto_mando_baseline_gpt/phrase_translation.ipynb#X32sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# Parallel(prefer=\"threads\", n_jobs=-1, verbose=2)(delayed(translate)(line) for line in input_file.read().splitlines()[0:100000])\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kevin/Dev/classes/winter2023/eecs487/canto_mando_baseline_gpt/phrase_translation.ipynb#X32sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m input_file\u001b[39m.\u001b[39mread()\u001b[39m.\u001b[39msplitlines()[\u001b[39m0\u001b[39m:\u001b[39m100000\u001b[39m]:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kevin/Dev/classes/winter2023/eecs487/canto_mando_baseline_gpt/phrase_translation.ipynb#X32sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         output_file\u001b[39m.\u001b[39mwrite(can2man(line\u001b[39m.\u001b[39;49mreplace(\u001b[39m\"\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m)) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/Users/kevin/Dev/classes/winter2023/eecs487/canto_mando_baseline_gpt/phrase_translation.ipynb Cell 23\u001b[0m in \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevin/Dev/classes/winter2023/eecs487/canto_mando_baseline_gpt/phrase_translation.ipynb#X32sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mfor\u001b[39;00m phrase \u001b[39min\u001b[39;00m man_phrases[i]:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevin/Dev/classes/winter2023/eecs487/canto_mando_baseline_gpt/phrase_translation.ipynb#X32sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     s \u001b[39m=\u001b[39m backward_context \u001b[39m+\u001b[39m phrase \u001b[39m+\u001b[39m forward_context\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kevin/Dev/classes/winter2023/eecs487/canto_mando_baseline_gpt/phrase_translation.ipynb#X32sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     ppl \u001b[39m=\u001b[39m score_sentence_ppl(s)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevin/Dev/classes/winter2023/eecs487/canto_mando_baseline_gpt/phrase_translation.ipynb#X32sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     \u001b[39m# print(s, ppl)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevin/Dev/classes/winter2023/eecs487/canto_mando_baseline_gpt/phrase_translation.ipynb#X32sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m ppl \u001b[39m<\u001b[39m best_ppl:\n",
      "\u001b[1;32m/Users/kevin/Dev/classes/winter2023/eecs487/canto_mando_baseline_gpt/phrase_translation.ipynb Cell 23\u001b[0m in \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevin/Dev/classes/winter2023/eecs487/canto_mando_baseline_gpt/phrase_translation.ipynb#X32sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m target_ids[:, :\u001b[39m-\u001b[39mtrg_len] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m100\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevin/Dev/classes/winter2023/eecs487/canto_mando_baseline_gpt/phrase_translation.ipynb#X32sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kevin/Dev/classes/winter2023/eecs487/canto_mando_baseline_gpt/phrase_translation.ipynb#X32sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model(input_ids, labels\u001b[39m=\u001b[39;49mtarget_ids)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevin/Dev/classes/winter2023/eecs487/canto_mando_baseline_gpt/phrase_translation.ipynb#X32sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39m# loss is calculated using CrossEntropyLoss which averages over input tokens.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevin/Dev/classes/winter2023/eecs487/canto_mando_baseline_gpt/phrase_translation.ipynb#X32sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39m# Multiply it with trg_len to get the summation instead of average.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevin/Dev/classes/winter2023/eecs487/canto_mando_baseline_gpt/phrase_translation.ipynb#X32sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39m# We will take average over all the tokens to get the true average\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevin/Dev/classes/winter2023/eecs487/canto_mando_baseline_gpt/phrase_translation.ipynb#X32sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39m# in the last step of this example.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevin/Dev/classes/winter2023/eecs487/canto_mando_baseline_gpt/phrase_translation.ipynb#X32sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     neg_log_likelihood \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mloss \u001b[39m*\u001b[39m trg_len\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:1075\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m \u001b[39m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[39m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m \u001b[39m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1075\u001b[0m transformer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(\n\u001b[1;32m   1076\u001b[0m     input_ids,\n\u001b[1;32m   1077\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1078\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1079\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1080\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1081\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1082\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1083\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1084\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m   1085\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1086\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1087\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1088\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1089\u001b[0m )\n\u001b[1;32m   1090\u001b[0m hidden_states \u001b[39m=\u001b[39m transformer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1092\u001b[0m \u001b[39m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:899\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    889\u001b[0m     outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    890\u001b[0m         create_custom_forward(block),\n\u001b[1;32m    891\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    896\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    897\u001b[0m     )\n\u001b[1;32m    898\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 899\u001b[0m     outputs \u001b[39m=\u001b[39m block(\n\u001b[1;32m    900\u001b[0m         hidden_states,\n\u001b[1;32m    901\u001b[0m         layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[1;32m    902\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    903\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask[i],\n\u001b[1;32m    904\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    905\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m    906\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    907\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    908\u001b[0m     )\n\u001b[1;32m    910\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    911\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:426\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    424\u001b[0m residual \u001b[39m=\u001b[39m hidden_states\n\u001b[1;32m    425\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_2(hidden_states)\n\u001b[0;32m--> 426\u001b[0m feed_forward_hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmlp(hidden_states)\n\u001b[1;32m    427\u001b[0m \u001b[39m# residual connection\u001b[39;00m\n\u001b[1;32m    428\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m feed_forward_hidden_states\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:355\u001b[0m, in \u001b[0;36mGPT2MLP.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    353\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc_fc(hidden_states)\n\u001b[1;32m    354\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(hidden_states)\n\u001b[0;32m--> 355\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mc_proj(hidden_states)\n\u001b[1;32m    356\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    357\u001b[0m \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/transformers/pytorch_utils.py:114\u001b[0m, in \u001b[0;36mConv1D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m    113\u001b[0m     size_out \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39msize()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnf,)\n\u001b[0;32m--> 114\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49maddmm(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, x\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, x\u001b[39m.\u001b[39;49msize(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight)\n\u001b[1;32m    115\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(size_out)\n\u001b[1;32m    116\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from joblib import Parallel, delayed\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "with open(\"cantonese_18M_freq_10_up.txt\", \"r\") as input_file, open(\"cantonese_18M_freq_10_up.pred.base.txt\", \"w+\") as output_file:\n",
    "    # Parallel(prefer=\"threads\", n_jobs=-1, verbose=2)(delayed(translate)(line) for line in input_file.read().splitlines()[0:100000])\n",
    "    for line in input_file.read().splitlines()[0:100000]:\n",
    "        output_file.write(can2man(line.replace(\" \", \"\")) + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
